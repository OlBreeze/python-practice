# –°–∫—Ä–∏–ø—Ç –ø–æ–≤–∏–Ω–µ–Ω –ø–æ—á–∞—Ç–∏ –∑ –ø–µ—Ä—à–æ—ó —Å—Ç–æ—Ä—ñ–Ω–∫–∏ (http://books.toscrape.com/).
# –°–∫—Ä–∏–ø—Ç –ø–æ–≤–∏–Ω–µ–Ω –æ–±—ñ–π—Ç–∏ –≤—Å—ñ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –∫–∞—Ç–∞–ª–æ–≥—É (–¥–æ 50 —Å—Ç–æ—Ä—ñ–Ω–æ–∫). üöÄ
# –î–ª—è –∫–æ–∂–Ω–æ—ó –∫–Ω–∏–≥–∏ –Ω–∞ –∫–æ–∂–Ω—ñ–π —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ –∑—ñ–±—Ä–∞—Ç–∏ —Ç–∞–∫—ñ –¥–∞–Ω—ñ:
# –ù–∞–∑–≤–∞ –∫–Ω–∏–≥–∏ (Title).
# –¶—ñ–Ω–∞ (Price, —É —Ñ—É–Ω—Ç–∞—Ö —Å—Ç–µ—Ä–ª—ñ–Ω–≥—ñ–≤).
# –†–µ–π—Ç–∏–Ω–≥ (Rating, —É –≤–∏–≥–ª—è–¥—ñ —Å–ª—ñ–≤, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "Three", "Five").
# –ù–∞—è–≤–Ω—ñ—Å—Ç—å –Ω–∞ —Å–∫–ª–∞–¥—ñ (Availability ‚Äì –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞, —á–∏ –ø—Ä–∏—Å—É—Ç–Ω—ñ–π —Ç–µ–∫—Å—Ç "In stock").
# –ó–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –†–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤:
# –ó—ñ–±—Ä–∞–Ω—ñ –¥–∞–Ω—ñ –º–∞—é—Ç—å –±—É—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω—ñ —É —Ñ–æ—Ä–º–∞—Ç—ñ CSV (Comma Separated Values) –∞–±–æ Excel.
# –ö–æ–∂–µ–Ω —Ä—è–¥–æ–∫ —É —Ñ–∞–π–ª—ñ –ø–æ–≤–∏–Ω–µ–Ω –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—Ç–∏ –æ–¥–Ω—ñ–π –∫–Ω–∏–∑—ñ.
# –§–∞–π–ª –ø–æ–≤–∏–Ω–µ–Ω –º–∞—Ç–∏ —á—ñ—Ç–∫—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–≤–ø—Ü—ñ–≤: –ù–∞–∑–≤–∞, –¶—ñ–Ω–∞, –†–µ–π—Ç–∏–Ω–≥, –ù–∞—è–≤–Ω—ñ—Å—Ç—å.
# –í–∏–º–æ–≥–∏ –¥–æ –†–µ–∞–ª—ñ–∑–∞—Ü—ñ—ó —Ç–∞ –ö—Ä–æ–∫–∏
# HTTP-–ó–∞–ø–∏—Ç (requests):
# –°—Ç–≤–æ—Ä—ñ—Ç—å —Ñ—É–Ω–∫—Ü—ñ—é, —è–∫–∞ –ø—Ä–∏–π–º–∞—î URL —ñ –ø–æ–≤–µ—Ä—Ç–∞—î –æ–±'—î–∫—Ç HTML-–≤—ñ–¥–ø–æ–≤—ñ–¥—ñ.
# –û–±—Ä–æ–±—ñ—Ç—å –º–æ–∂–ª–∏–≤—ñ –ø–æ–º–∏–ª–∫–∏ –∑–∞–ø–∏—Ç—É (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –∫–æ–¥–∏ 404, 500) –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó try...except.
# –ü–∞—Ä—Å–∏–Ω–≥ HTML (BeautifulSoup):
# –°—Ç–≤–æ—Ä—ñ—Ç—å —Ñ—É–Ω–∫—Ü—ñ—é, —è–∫–∞ –ø—Ä–∏–π–º–∞—î HTML-–∫–æ–Ω—Ç–µ–Ω—Ç —ñ –ø–∞—Ä—Å–∏—Ç—å –π–æ–≥–æ, –∑–Ω–∞—Ö–æ–¥—è—á–∏ –≤—Å—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ –∫–Ω–∏–≥.
# –î–ª—è –∫–æ–∂–Ω–æ–≥–æ –µ–ª–µ–º–µ–Ω—Ç–∞ –∫–Ω–∏–≥–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –º–µ—Ç–æ–¥–∏ find() –∞–±–æ select_one() –¥–ª—è –≤–∏–ª—É—á–µ–Ω–Ω—è –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö:
# –ù–∞–∑–≤–∞: –∑–∞–∑–≤–∏—á–∞–π –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ —Ç–µ–≥—É <h3> –∞–±–æ –ø–æ—Å–∏–ª–∞–Ω–Ω—è–º <a> –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ.
# –¶—ñ–Ω–∞: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–π CSS-–∫–ª–∞—Å, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥, .price_color.
# –†–µ–π—Ç–∏–Ω–≥: —à—É–∫–∞–π—Ç–µ –∫–ª–∞—Å, —â–æ –ø–æ—á–∏–Ω–∞—î—Ç—å—Å—è –∑ star-rating, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥, class="star-rating Three".
# –ù–∞–≤—ñ–≥–∞—Ü—ñ—è:
# –†–µ–∞–ª—ñ–∑—É–π—Ç–µ –ª–æ–≥—ñ–∫—É –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥—É –¥–æ –Ω–∞—Å—Ç—É–ø–Ω–æ—ó —Å—Ç–æ—Ä—ñ–Ω–∫–∏, —à—É–∫–∞—é—á–∏ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –∑ —Ç–µ–∫—Å—Ç–æ–º "next" –∞–±–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–º CSS-–∫–ª–∞—Å–æ–º —É –Ω–∏–∂–Ω—ñ–π —á–∞—Å—Ç–∏–Ω—ñ –ø–æ—Ç–æ—á–Ω–æ—ó —Å—Ç–æ—Ä—ñ–Ω–∫–∏.
# –û—á–∏—â–µ–Ω–Ω—è –î–∞–Ω–∏—Ö (Data Cleaning):
# –¶—ñ–Ω–∞: –ü—Ä–∏–±–µ—Ä—ñ—Ç—å —Å–∏–º–≤–æ–ª –≤–∞–ª—é—Ç–∏ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, ¬£) —Ç–∞ –ø–µ—Ä–µ—Ç–≤–æ—Ä—ñ—Ç—å –∑–Ω–∞—á–µ–Ω–Ω—è –Ω–∞ —á–∏—Å–ª–æ–≤–µ (float).
# –ù–∞—è–≤–Ω—ñ—Å—Ç—å: –ü–µ—Ä–µ—Ç–≤–æ—Ä—ñ—Ç—å —Ç–µ–∫—Å—Ç–æ–≤–µ –∑–Ω–∞—á–µ–Ω–Ω—è –Ω–∞ –±—É–ª–µ–≤–µ (True/False –∞–±–æ –¢–∞–∫/–ù—ñ).
# –†–µ–π—Ç–∏–Ω–≥: –í–∏–¥—ñ–ª—ñ—Ç—å —Å–∞–º–µ —Å–ª–æ–≤–æ-—Ä–µ–π—Ç–∏–Ω–≥ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, Three).
# –û—á—ñ–∫—É–≤–∞–Ω–∏–π –†–µ–∑—É–ª—å—Ç–∞—Ç
# –§–∞–π–ª, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥, books_data.csv, —â–æ –º—ñ—Å—Ç–∏—Ç—å —Å–æ—Ç–Ω—ñ —Ä—è–¥–∫—ñ–≤ (–ø–æ –æ–¥–Ω—ñ–π –∫–Ω–∏–∑—ñ) –∑ —á—ñ—Ç–∫–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏.
# –ù–∞–∑–≤–∞Ôæ†–¶—ñ–Ω–∞Ôæ†–†–µ–π—Ç–∏–Ω–≥Ôæ†–ù–∞—è–≤–Ω—ñ—Å—Ç—å
# A Light in the AtticÔæ†51.77Ôæ†ThreeÔæ†True
# Tipping the VelvetÔæ†53.74Ôæ†OneÔæ†True
# ...Ôæ†...Ôæ†...Ôæ†...
# The Secret GardenÔæ†15.00Ôæ†TwoÔæ†True


import requests
from bs4 import BeautifulSoup
import csv
import time


def scrape_books(url, max_pages=5):
    """
    –°–∫—Ä–µ–π–ø–µ—Ä –¥–ª—è –∑–±–æ—Ä—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –∫–Ω–∏–≥–∏

    Args:
        url: URL —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É
        max_pages: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Å—Ç–æ—Ä—ñ–Ω–æ–∫ –¥–ª—è –æ–±—Ä–æ–±–∫–∏
    """
    all_books = []

    for page in range(1, max_pages + 1):
        print(f"–û–±—Ä–æ–±–∫–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ {page}...")

        # –§–æ—Ä–º—É—î–º–æ URL –∑ –Ω–æ–º–µ—Ä–æ–º —Å—Ç–æ—Ä—ñ–Ω–∫–∏
        page_url = f"{url}catalogue/page-{page}.html"

        try:
            # –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ –∑–∞–ø–∏—Ç
            response = requests.get(page_url)
            response.raise_for_status()

            # –ü–∞—Ä—Å–∏–º–æ HTML
            soup = BeautifulSoup(response.content, 'html.parser')

            # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ –∫–Ω–∏–≥–∏ –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ
            books = soup.find_all('article', class_='product_pod')

            for book in books:
                # –í–∏—Ç—è–≥—É—î–º–æ –¥–∞–Ω—ñ
                title = book.h3.a['title']
                price_text = book.find('p', class_='price_color').text
                price = ''.join(char for char in price_text if char.isdigit() or char == '.')
                price = price.strip()
                availability = "In stock" in book.find('p', class_='instock availability').text

                # –†–µ–π—Ç–∏–Ω–≥ (–ø–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ —Ç–µ–∫—Å—Ç–æ–≤–∏–π —É —á–∏—Å–ª–æ–≤–∏–π)
                rating_class = book.find('p', class_='star-rating')['class'][1]
                # rating_map = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}
                # rating = rating_map.get(rating_class, 0)

                all_books.append({
                    '–Ω–∞–∑–≤–∞': title,
                    '—Ü—ñ–Ω–∞': price,
                    '–Ω–∞—è–≤–Ω—ñ—Å—Ç—å': availability,
                    '—Ä–µ–π—Ç–∏–Ω–≥': rating_class
                })

            print(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(books)} –∫–Ω–∏–≥ –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ {page}")

            # –î–æ–¥–∞—î–º–æ –∑–∞—Ç—Ä–∏–º–∫—É –º—ñ–∂ –∑–∞–ø–∏—Ç–∞–º–∏
            time.sleep(1)

        except requests.RequestException as e:
            print(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Ç—ñ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ {page}: {e}")
            break

    return all_books


def save_to_csv(books, filename='books.csv'):
    """–ó–±–µ—Ä—ñ–≥–∞—î –¥–∞–Ω—ñ –≤ CSV —Ñ–∞–π–ª"""
    if not books:
        print("–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è")
        return

    with open(filename, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=books[0].keys())
        writer.writeheader()
        writer.writerows(books)

    print(f"–î–∞–Ω—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É {filename}")


def main():
    # URL –¥–µ–º–æ-—Å–∞–π—Ç—É –¥–ª—è –ø—Ä–∞–∫—Ç–∏–∫–∏ scraping
    base_url = "http://books.toscrape.com/"

    print("–ó–∞–ø—É—Å–∫ —Å–∫—Ä–µ–π–ø–µ—Ä–∞...")
    books = scrape_books(base_url, max_pages=3)

    print(f"\n–£—Å—å–æ–≥–æ –∑—ñ–±—Ä–∞–Ω–æ –∫–Ω–∏–≥: {len(books)}")

    # –ü–æ–∫–∞–∑—É—î–º–æ –ø–µ—Ä—à—ñ 5 –∫–Ω–∏–≥
    print("\n–ü—Ä–∏–∫–ª–∞–¥ –¥–∞–Ω–∏—Ö (–ø–µ—Ä—à—ñ 5 –∫–Ω–∏–≥):")
    for i, book in enumerate(books[:5], 1):
        print(f"\n{i}. {book['–Ω–∞–∑–≤–∞']}")
        print(f"  –¶—ñ–Ω–∞: {book['—Ü—ñ–Ω–∞']}")
        print(f"  –†–µ–π—Ç–∏–Ω–≥: {book['—Ä–µ–π—Ç–∏–Ω–≥']}")
        print(f"  –ù–∞—è–≤–Ω—ñ—Å—Ç—å: {book['–Ω–∞—è–≤–Ω—ñ—Å—Ç—å']}")

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ CSV
    save_to_csv(books)

if __name__ == "__main__":
    main()
#
# requests.get() - –æ—Ç—Ä–∏–º—É—î–º–æ HTML —Å—Ç–æ—Ä—ñ–Ω–∫–∏
# BeautifulSoup - –ø–∞—Ä—Å–∏–º–æ HTML —Ç–∞ –≤–∏—Ç—è–≥—É—î–º–æ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –µ–ª–µ–º–µ–Ω—Ç–∏
# find() —ñ find_all() - —à—É–∫–∞—î–º–æ –µ–ª–µ–º–µ–Ω—Ç–∏ –∑–∞ —Ç–µ–≥–∞–º–∏ —Ç–∞ –∫–ª–∞—Å–∞–º–∏
# time.sleep(1) - –∑–∞—Ç—Ä–∏–º–∫–∞ –º—ñ–∂ –∑–∞–ø–∏—Ç–∞–º–∏ (–≤–∞–∂–ª–∏–≤–æ!)
# –û–±—Ä–æ–±–∫–∞ –ø–æ–º–∏–ª–æ–∫ —á–µ—Ä–µ–∑ try/except